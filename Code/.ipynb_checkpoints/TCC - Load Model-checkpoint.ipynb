{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# `do not disturb` mode\n",
    "import warnings                                  \n",
    "warnings.filterwarnings('ignore')\n",
    "                           \n",
    "# Dates Manipulation\n",
    "from dateutil.relativedelta import relativedelta \n",
    "from datetime import datetime, timedelta\n",
    "import holidays\n",
    "import calendar\n",
    "\n",
    "# statistics\n",
    "import statsmodels.formula.api as smf            \n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Signal Processing\n",
    "import scipy as sp\n",
    "import scipy.fftpack\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "params = {'figure.figsize': [10, 12], \n",
    "          'axes.labelsize': 16,\n",
    "          'axes.titlesize':18, \n",
    "          'font.size': 16,\n",
    "          'legend.fontsize': 12, \n",
    "          'xtick.labelsize': 12, \n",
    "          'ytick.labelsize': 12\n",
    "         }\n",
    "\n",
    "plt.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seta display de x linhas\n",
    "pd.set_option('display.max_row', 100)\n",
    "# Seta display de x colunas\n",
    "pd.set_option('display.max_columns', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######  function [GRNN]=grnn_v1(p,t,spread) #######\n",
    "def train_matrix(p, t, spread):\n",
    "    #Cria Matriz de Treinamento: \n",
    "    \n",
    "    # p -> Matriz contendo os vetores de entrada\n",
    "    # t -> Matriz contendo os vetores de saída\n",
    "    # spread -> valor do spread que será utilizado\n",
    "    \n",
    "    #Cria matriz com as matrizes de entrada p e t\n",
    "    GRNN=np.zeros((1+t.shape[0]+p.shape[0],t.shape[1]))\n",
    "    \n",
    "    # Verifica o número de padrões utilizados no treinamento \"n\"\n",
    "    if p.shape[1] == t.shape[1]: \n",
    "        # número de entradas do vetor de entrada \"ne\"\n",
    "        GRNN[0,0]=p.shape[0]\n",
    "        # número de saídas do vetor de saída \"ns\"\n",
    "        GRNN[0,1]=t.shape[0]\n",
    "        # Spread\n",
    "        GRNN[0,2]=spread\n",
    "        \n",
    "        #vetores de entrada P\n",
    "        GRNN[1:1+p.shape[0],:]=p\n",
    "        #Vetores de saída T\n",
    "        GRNN[1+p.shape[0]:1+p.shape[0]+t.shape[0],:]=t\n",
    "    return GRNN;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Função que implementa a GRNN #######\n",
    "\n",
    "def implementa_grnn(GRNN, X): \n",
    "    \n",
    "    # GRNN - Saída da Função grnn_v1(p,t,spread) #\n",
    "    # X    - Valor a ser aproximado #\n",
    "\n",
    "    # Definição de ne, n\n",
    "    sizep = [GRNN[0,0], GRNN.shape[1]] \n",
    "    \n",
    "    # Definição de ns, n\n",
    "    sizet = [GRNN[0,1], GRNN.shape[1]] \n",
    "    \n",
    "    # Parâmetro spread\n",
    "    spread = GRNN[0,2]\n",
    "\n",
    "    \n",
    "    p = GRNN[1:1+int(sizep[0]),:]\n",
    "    t = GRNN[1+int(sizep[0]):1+int(sizep[0])+int(sizet[0]),:]\n",
    "\n",
    "    c1 = np.zeros((int(sizep[0]),int(sizep[1])))\n",
    "    c3 = np.zeros((1,int(sizep[1])))\n",
    "    \n",
    "    num = np.zeros((int(sizet[0]),int(sizet[1])))\n",
    "    den = np.copy(c3)\n",
    "    \n",
    "    Y = np.zeros((int(sizet[0]),np.size(X,1)))\n",
    "    A = np.zeros((int(sizep[0]),int(sizep[1])))\n",
    "\n",
    "    if (p.shape[0] == X.shape[0]):\n",
    "        for i in range(X.shape[1]):\n",
    "            for k in range(int(sizep[0])):\n",
    "                A[k,:] = X[k,i]*np.ones((1,int(sizep[1])))\n",
    "            c1 = abs(A-p)**2\n",
    "            # soma \"MATRIZ\"\n",
    "            c2 = np.sqrt(c1.sum(axis=0)) \n",
    "            \n",
    "    ########### Aqui é a GRNN ########### \n",
    "\n",
    "            for j in range(int(sizep[1])): \n",
    "                c3[0,j] = (1)*np.exp(-(0.8326*c2[j]/spread)**2)\n",
    "                for k in range(int(sizet[0])):\n",
    "                    num[k,j] = t[k,j]*c3[0,j]\n",
    "                den[0,j] = c3[0,j]\n",
    "                \n",
    "    ########################################\n",
    "\n",
    "            for k in range(int(sizet[0])):\n",
    "                #Y(k,i)=sum(num(k,:)/(sum(den)+1e-9)\n",
    "                Y[k,i]=(np.sum(num[k,:])/(np.sum(den)+0.0000000001))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRNN Modificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Função que implementa a GRNN Modificada #######\n",
    "\n",
    "def implementa_grnn_mod(GRNN, X, nmax): \n",
    "    \n",
    "    # GRNN - Saída da Função grnn_v1(p,t,spread) #\n",
    "    # X    - Valor a ser aproximado #\n",
    "    \n",
    "    # Definição de ne, n\n",
    "    sizep=[GRNN[0,0], GRNN.shape[1]]\n",
    "    \n",
    "    # Definição de ns, n\n",
    "    sizet=[GRNN[0,1], GRNN.shape[1]] \n",
    "    \n",
    "    # Parâmetro spread\n",
    "    spread=GRNN[0,2]\n",
    "\n",
    "    p=GRNN[1:1+int(sizep[0]),:]\n",
    "    t=GRNN[1+int(sizep[0]):1+int(sizep[0])+int(sizet[0]),:]\n",
    "\n",
    "    c1=np.zeros((int(sizep[0]),int(sizep[1])))\n",
    "    c3=np.zeros((1,nmax))\n",
    "\n",
    "    num=np.zeros((int(sizet[0]),int(sizet[1])))\n",
    "    den=np.copy(c3)\n",
    "    \n",
    "    Y=np.zeros((int(sizet[0]), X.shape[1]))\n",
    "    A=np.zeros((int(sizep[0]),int(sizep[1])))\n",
    "    \n",
    "    if (p.shape[0] == X.shape[0]):\n",
    "        for i in range(X.shape[1]):      \n",
    "            for k in range(int(sizep[0])):\n",
    "                A[k,:]=X[k,i]*np.ones((1,int(sizep[1])))\n",
    "            \n",
    "            c1=abs(A-p)**2\n",
    "            \n",
    "            # soma \"MATRIZ\"\n",
    "            c2=np.sqrt(c1.sum(axis=0))\n",
    "\n",
    "########### Aqui é a GRNN modificada ###########\n",
    "        \n",
    "            ind_c2 = np.argsort(c2)\n",
    "            ord_c2 = np.sort(c2)\n",
    "        \n",
    "            for j in range(nmax): \n",
    "                \n",
    "                c3[0,j]=(1)*np.exp(-(0.8326*ord_c2[j]/spread)**2)\n",
    "                \n",
    "                for k in range(int(sizet[0])):\n",
    "                    \n",
    "                    num[k,j]=t[k,ind_c2[j]]*c3[0,j]\n",
    "                    \n",
    "                den[0,j]=c3[0,j]\n",
    "                \n",
    "####################################################\n",
    "            \n",
    "            for k in range(int(sizet[0])):\n",
    "                Y[k,i]=(np.sum(num[k,:])/(np.sum(den)+0.0000000001))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred): \n",
    "    return np.max(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtra os datasets para o ano de 2018\n",
    "\n",
    "def filteryear(df):\n",
    "    df = df[(df['year']) == 2018]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normaliza os valorews de carga\n",
    "\n",
    "def normalize(df, new_column, column):\n",
    "    df[new_column] = df[column]/max(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time(df):\n",
    "    df['time'] = df['data_medicao'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pega o mês de Referência\n",
    "\n",
    "def get_month(df):\n",
    "    df['inp_month'] = df['month']/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pega dummies para os dias da semana\n",
    "\n",
    "def getmon(df):\n",
    "    \n",
    "    if df['week_day'] == 'MONDAY' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def gettue_res(df):    \n",
    "    if df['week_day'] == 'TUESDAY' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def getwed_res(df):    \n",
    "    if df['week_day'] == 'WEDNESDAY' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "def getthu_res(df):       \n",
    "    if df['week_day'] == 'THURSDAY' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def getfri_res(df):       \n",
    "    if df['week_day'] == 'FRIDAY' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def getsat(df):       \n",
    "    if df['week_day'] == 'SATURDAY' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def getsun(df):           \n",
    "    if df['week_day'] == 'SUNDAY' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def getweek_ot(df):    \n",
    "    if df['week_day'] == 'TUESDAY' or df['week_day'] == 'WEDNESDAY' or\\\n",
    "    df['week_day'] == 'THURSDAY' or df['week_day'] == 'FRIDAY':\n",
    "        return 1\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residential_stats(df):\n",
    "    df['is_monday'] = df.apply (lambda row: getmon(row), axis=1)\n",
    "\n",
    "    df['is_tuesday'] = df.apply (lambda row: gettue_res(row), axis=1)\n",
    "\n",
    "    df['is_wednesday'] = df.apply (lambda row: getwed_res(row), axis=1)\n",
    "    \n",
    "    df['is_thursday'] = df.apply (lambda row: getthu_res(row), axis=1)\n",
    "    \n",
    "    df['is_friday'] = df.apply (lambda row: getfri_res(row), axis=1)\n",
    "    \n",
    "    df['is_saturday'] = df.apply (lambda row: getsat(row), axis=1)\n",
    "    \n",
    "    df['is_sunday'] = df.apply (lambda row: getsun(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_stats(df):\n",
    "    df['is_monday'] = df.apply (lambda row: getmon(row), axis=1)\n",
    "\n",
    "    df['is_week'] = df.apply (lambda row: getweek_ot(row), axis=1)\n",
    "\n",
    "    df['is_saturday'] = df.apply (lambda row: getsat(row), axis=1)\n",
    "    \n",
    "    df['is_sunday'] = df.apply (lambda row: getsun(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_statistics(df, column1, column2):\n",
    "    \n",
    "    # Input: df receives dataframe and column receives string\n",
    "\n",
    "    result = df.groupby(column1)[column2].agg(['min','max','mean'])\n",
    "    shift_df = result.shift(periods=1, fill_value=0).reset_index()\n",
    "\n",
    "    return shift_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Definindo os nomes das colunas\n",
    "typing = {'instalacao': 'str'}\n",
    "\n",
    "#importando o arquivo - Dataset de dados de carga Residenciais\n",
    "data_res = pd.read_csv(r'C:/Users/vitmi/Desktop/TCC/Data/load_data/Data_res_mean.csv', encoding='utf-8', \n",
    "                       sep = ';', decimal = '.',  dtype = typing, parse_dates = ['data_medicao'])\n",
    "data_res = filteryear(data_res)\n",
    "get_month(data_res)\n",
    "extract_time(data_res)\n",
    "normalize(data_res, 'valor_kwh_n', 'valor_kwh')\n",
    "\n",
    "\n",
    "#importando o arquivo - Dataset de dados de carga Comerciais\n",
    "data_com = pd.read_csv(r'C:/Users/vitmi/Desktop/TCC/Data/load_data/data_com_mean.csv', encoding='utf-8', \n",
    "                       sep = ';', decimal = '.',  dtype = typing, parse_dates = ['data_medicao'])\n",
    "data_com = filteryear(data_com)\n",
    "get_month(data_com)\n",
    "extract_time(data_com)\n",
    "normalize(data_com, 'valor_kwh_n', 'valor_kwh')\n",
    "\n",
    "#importando o arquivo - Dataset de dados de carga - Poder Público Municipal\n",
    "data_ppm = pd.read_csv(r'C:/Users/vitmi/Desktop/TCC/Data/load_data/Data_ppm_mean.csv', encoding='utf-8', \n",
    "                       sep = ';', decimal = '.',  dtype = typing, parse_dates = ['data_medicao'])\n",
    "data_ppm = filteryear(data_ppm)\n",
    "get_month(data_ppm)\n",
    "extract_time(data_ppm)\n",
    "normalize(data_ppm, 'valor_kwh_n', 'valor_kwh')\n",
    "\n",
    "#importando o arquivo - Dataset de dados de carga - Serviço Público - Água, Saneamento e Esgoto\n",
    "data_sp = pd.read_csv(r'C:/Users/vitmi/Desktop/TCC/Data/load_data/Data_sp_mean.csv', encoding='utf-8', \n",
    "                       sep = ';', decimal = '.',  dtype = typing, parse_dates = ['data_medicao'])\n",
    "data_sp = filteryear(data_sp)\n",
    "get_month(data_sp)\n",
    "extract_time(data_sp)\n",
    "normalize(data_sp, 'valor_kwh_n', 'valor_kwh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_res_group = pd.DataFrame(data_res.groupby(by = ['data_med', 'inp_month', 'hora_verao', 'feriado', 'week_day'])\\\n",
    "                                 ['valor_kwh'].mean()).reset_index(drop = False)\n",
    "residential_stats(data_res_group)\n",
    "data_res_group = data_res_group.drop(columns=['data_med', 'valor_kwh', 'week_day'])\n",
    "\n",
    "\n",
    "data_com_group = pd.DataFrame(data_com.groupby(by = ['data_med', 'inp_month', 'hora_verao', 'feriado', 'week_day'])\\\n",
    "                                 ['valor_kwh'].mean()).reset_index(drop = False)\n",
    "other_stats(data_com_group)\n",
    "data_com_group = data_com_group.drop(columns=['data_med', 'valor_kwh', 'week_day'])\n",
    "\n",
    "\n",
    "data_ppm_group = pd.DataFrame(data_ppm.groupby(by = ['data_med', 'inp_month', 'hora_verao', 'feriado', 'week_day'])\\\n",
    "                                 ['valor_kwh'].mean()).reset_index(drop = False)\n",
    "other_stats(data_ppm_group)\n",
    "data_ppm_group = data_ppm_group.drop(columns=['data_med', 'valor_kwh', 'week_day'])\n",
    "\n",
    "\n",
    "data_sp_group = pd.DataFrame(data_sp.groupby(by = ['data_med', 'inp_month', 'hora_verao', 'feriado', 'week_day'])\\\n",
    "                                 ['valor_kwh'].mean()).reset_index(drop = False)\n",
    "other_stats(data_sp_group)\n",
    "data_sp_group = data_sp_group.drop(columns=['data_med', 'valor_kwh', 'week_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_res_stats = load_statistics(data_res, 'data_med', 'valor_kwh_n')\n",
    "data_com_stats = load_statistics(data_com, 'data_med', 'valor_kwh_n')\n",
    "data_ppm_stats = load_statistics(data_ppm, 'data_med', 'valor_kwh_n')\n",
    "data_sp_stats = load_statistics(data_sp, 'data_med', 'valor_kwh_n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de entrada X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod_res = pd.concat([data_res_group, data_res_stats], axis=1, join=\"inner\").set_index(['data_med'])\n",
    "data_mod_com = pd.concat([data_com_group, data_com_stats], axis=1, join=\"inner\").set_index(['data_med'])\n",
    "data_mod_ppm = pd.concat([data_ppm_group, data_ppm_stats], axis=1, join=\"inner\").set_index(['data_med'])\n",
    "data_mod_sp = pd.concat([data_sp_group, data_sp_stats], axis=1, join=\"inner\").set_index(['data_med'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treino, Validação e Teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod_res_tre = data_mod_res[(data_mod_res['inp_month']*12 < 9)]\n",
    "data_mod_res_tre_m = np.matrix(data_mod_res_tre.T)\n",
    "\n",
    "data_mod_res_val = data_mod_res[(data_mod_res['inp_month']*12 < 12) & (data_mod_res['inp_month']*12 > 8) ]\n",
    "data_mod_res_val_m = np.matrix(data_mod_res_val.T)\n",
    "\n",
    "data_mod_res_teste1 = data_mod_res.loc[(data_mod_res.index > '2018-11-30') & (data_mod_res.index < '2018-12-09')]\n",
    "data_mod_res_teste1_m = np.matrix(data_mod_res_teste1.T)\n",
    "\n",
    "data_mod_res_teste2 = data_mod_res.loc[(data_mod_res.index > '2018-12-22') & (data_mod_res.index < '2018-12-30')]\n",
    "data_mod_res_teste2_m = np.matrix(data_mod_res_teste2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod_com_tre = data_mod_com[(data_mod_com['inp_month']*12 < 9)]\n",
    "data_mod_com_tre_m = np.matrix(data_mod_com_tre.T)\n",
    "\n",
    "data_mod_com_val = data_mod_com[(data_mod_com['inp_month']*12 < 12) & (data_mod_com['inp_month']*12 > 8) ]\n",
    "data_mod_com_val_m = np.matrix(data_mod_com_val.T)\n",
    "\n",
    "data_mod_com_teste1 = data_mod_com.loc[(data_mod_com.index > '2018-11-30') & (data_mod_com.index < '2018-12-09')]\n",
    "data_mod_com_teste1_m = np.matrix(data_mod_com_teste1.T)\n",
    "\n",
    "data_mod_com_teste2 = data_mod_com.loc[(data_mod_com.index > '2018-12-22') & (data_mod_com.index < '2018-12-30')]\n",
    "data_mod_com_teste2_m = np.matrix(data_mod_com_teste2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod_ppm_tre = data_mod_ppm[(data_mod_ppm['inp_month']*12 < 9)]\n",
    "data_mod_ppm_tre_m = np.matrix(data_mod_ppm_tre.T)\n",
    "\n",
    "data_mod_ppm_val = data_mod_ppm[(data_mod_ppm['inp_month']*12 < 12) & (data_mod_ppm['inp_month']*12 > 8) ]\n",
    "data_mod_ppm_val_m = np.matrix(data_mod_ppm_val.T)\n",
    "\n",
    "data_mod_ppm_teste1 = data_mod_ppm.loc[(data_mod_ppm.index > '2018-11-30') & (data_mod_ppm.index < '2018-12-09')]\n",
    "data_mod_ppm_teste1_m = np.matrix(data_mod_ppm_teste1.T)\n",
    "\n",
    "data_mod_ppm_teste2 = data_mod_ppm.loc[(data_mod_ppm.index > '2018-12-22') & (data_mod_ppm.index < '2018-12-30')]\n",
    "data_mod_ppm_teste2_m = np.matrix(data_mod_ppm_teste2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod_sp_tre = data_mod_sp[(data_mod_sp['inp_month']*12 < 9)]\n",
    "data_mod_sp_tre_m = np.matrix(data_mod_sp_tre.T)\n",
    "\n",
    "data_mod_sp_val = data_mod_sp[(data_mod_sp['inp_month']*12 < 12) & (data_mod_sp['inp_month']*12 > 8) ]\n",
    "data_mod_sp_val_m = np.matrix(data_mod_sp_val.T)\n",
    "\n",
    "data_mod_sp_teste1 = data_mod_sp.loc[(data_mod_sp.index > '2018-11-30') & (data_mod_sp.index < '2018-12-09')]\n",
    "data_mod_sp_teste1_m = np.matrix(data_mod_sp_teste1.T)\n",
    "\n",
    "data_mod_sp_teste2 = data_mod_sp.loc[(data_mod_sp.index > '2018-12-22') & (data_mod_sp.index < '2018-12-30')]\n",
    "data_mod_sp_teste2_m = np.matrix(data_mod_sp_teste2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Saída Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_res = pd.pivot_table(data_res, values = 'valor_kwh_n', columns='data_med', index = 'time')\n",
    "data_out_com = pd.pivot_table(data_com, values = 'valor_kwh_n', columns='data_med', index = 'time')\n",
    "data_out_ppm = pd.pivot_table(data_ppm, values = 'valor_kwh_n', columns='data_med', index = 'time')\n",
    "data_out_sp = pd.pivot_table(data_sp, values = 'valor_kwh_n', columns='data_med', index = 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treino, Validação e Teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_res_tre = data_out_res.T.loc[(data_out_res.T.index <= '2018-08-31')].T\n",
    "data_out_res_tre_m = np.matrix(data_out_res_tre)\n",
    "\n",
    "data_out_res_val = data_out_res.T.loc[(data_out_res.T.index <= '2018-11-30') & (data_out_res.T.index >= '2018-09-01')].T\n",
    "data_out_res_val_m = np.matrix(data_out_res_val)\n",
    "\n",
    "data_out_res_teste1 = data_out_res.T.loc[(data_out_res.T.index >= '2018-12-01') & (data_out_res.T.index <= '2018-12-08')].T\n",
    "data_out_res_teste1_m = np.matrix(data_out_res_teste1)\n",
    "\n",
    "data_out_res_teste2 = data_out_res.T.loc[(data_out_res.T.index >= '2018-12-23') & (data_out_res.T.index <= '2018-12-29')].T\n",
    "data_out_res_teste2_m = np.matrix(data_out_res_teste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_com_tre = data_out_com.T.loc[(data_out_com.T.index <= '2018-08-31')].T\n",
    "data_out_com_tre_m = np.matrix(data_out_com_tre)\n",
    "\n",
    "data_out_com_val = data_out_com.T.loc[(data_out_com.T.index <= '2018-11-30') & (data_out_com.T.index >= '2018-09-01')].T\n",
    "data_out_com_val_m = np.matrix(data_out_com_val)\n",
    "\n",
    "data_out_com_teste1 = data_out_com.T.loc[(data_out_com.T.index >= '2018-12-01') & (data_out_com.T.index <= '2018-12-08')].T\n",
    "data_out_com_teste1_m = np.matrix(data_out_com_teste1)\n",
    "\n",
    "data_out_com_teste2 = data_out_com.T.loc[(data_out_com.T.index >= '2018-12-23') & (data_out_com.T.index <= '2018-12-29')].T\n",
    "data_out_com_teste2_m = np.matrix(data_out_com_teste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_ppm_tre = data_out_ppm.T.loc[(data_out_ppm.T.index <= '2018-08-31')].T\n",
    "data_out_ppm_tre_m = np.matrix(data_out_ppm_tre)\n",
    "\n",
    "data_out_ppm_val = data_out_ppm.T.loc[(data_out_ppm.T.index <= '2018-11-30') & (data_out_ppm.T.index >= '2018-09-01')].T\n",
    "data_out_ppm_val_m = np.matrix(data_out_ppm_val)\n",
    "\n",
    "data_out_ppm_teste1 = data_out_ppm.T.loc[(data_out_ppm.T.index >= '2018-12-01') & (data_out_ppm.T.index <= '2018-12-08')].T\n",
    "data_out_ppm_teste1_m = np.matrix(data_out_ppm_teste1)\n",
    "\n",
    "data_out_ppm_teste2 = data_out_ppm.T.loc[(data_out_ppm.T.index >= '2018-12-23') & (data_out_ppm.T.index <= '2018-12-29')].T\n",
    "data_out_ppm_teste2_m = np.matrix(data_out_ppm_teste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_sp_tre = data_out_sp.T.loc[(data_out_sp.T.index <= '2018-08-31')].T\n",
    "data_out_sp_tre_m = np.matrix(data_out_sp_tre)\n",
    "\n",
    "data_out_sp_val = data_out_sp.T.loc[(data_out_sp.T.index <= '2018-11-30') & (data_out_sp.T.index >= '2018-09-01')].T\n",
    "data_out_sp_val_m = np.matrix(data_out_sp_val)\n",
    "\n",
    "data_out_sp_teste1 = data_out_sp.T.loc[(data_out_sp.T.index >= '2018-12-01') & (data_out_sp.T.index <= '2018-12-08')].T\n",
    "data_out_sp_teste1_m = np.matrix(data_out_sp_teste1)\n",
    "\n",
    "data_out_sp_teste2 = data_out_sp.T.loc[(data_out_sp.T.index >= '2018-12-23') & (data_out_sp.T.index <= '2018-12-29')].T\n",
    "data_out_sp_teste2_m = np.matrix(data_out_sp_teste2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRNN - Modelo Comercial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_mod_com_tre_m\n",
    "#data_mod_com_val_m\n",
    "#data_mod_com_teste1_m\n",
    "#data_mod_com_teste2_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_out_com_tre_m\n",
    "#data_out_com_val_m\n",
    "#data_out_com_teste1_m\n",
    "#data_out_com_teste2_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRNN_com = train_matrix(data_mod_com_tre_m, data_out_com_tre_m, spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 243)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRNN_com.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implementa_grnn(GRNN_com, data_out_com_val_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
